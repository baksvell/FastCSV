# План оптимизации FastCSV

## Анализ текущих результатов бенчмарка

### ✅ Сильные стороны
- **Medium files (500-2000 rows)**: 1.27x - 2.42x быстрее
- **Files with quotes**: 1.06x быстрее
- **Files with unicode**: 1.12x быстрее

### ⚠️ Проблемные области

#### 1. Большие файлы (>5000 rows) - КРИТИЧНО
**Текущая производительность:**
- Medium (5000 rows): **2.57x медленнее**
- Large (10000 rows): **2.48x медленнее**

**Причины:**
- Размер чанка 256KB может быть неоптимальным для больших файлов
- Множественные вызовы `parse_chunk_to_python` создают overhead
- Недостаточное использование batch processing
- Возможно, слишком много проверок в цикле парсинга

**Решения:**
1. **Увеличить размер чанка для больших файлов**
   - Для файлов >1MB использовать чанки 512KB-1MB
   - Ожидаемый прирост: 20-30%

2. **Оптимизировать parse_chunk для больших файлов**
   - Уменьшить количество проверок в циклах
   - Использовать более агрессивный batch processing
   - Ожидаемый прирост: 15-25%

3. **Оптимизировать создание Python объектов**
   - Batch создание всех объектов за один проход
   - Использовать PyList_New с предварительным размером
   - Ожидаемый прирост: 10-15%

#### 2. Широкие файлы (50 полей) - ВАЖНО
**Текущая производительность:**
- Wide (1000 rows, 50 fields): **1.04x медленнее**
- Wide with quotes (1000 rows, 50 fields): **1.14x медленнее**

**Причины:**
- Больше полей = больше вызовов `emplace_back`
- Больше проверок в циклах парсинга
- Больше выделений памяти для полей

**Решения:**
1. **Оптимизировать резервирование памяти для широких файлов**
   - Более точная оценка количества полей
   - Предварительное резервирование всех полей
   - Ожидаемый прирост: 10-15%

2. **Улучшить batch создание полей**
   - Использовать `reserve` для всего вектора полей заранее
   - Минимизировать реаллокации
   - Ожидаемый прирост: 5-10%

3. **Оптимизировать поиск разделителей для широких файлов**
   - Использовать SIMD для поиска всех разделителей за один проход
   - Кэшировать позиции разделителей
   - Ожидаемый прирост: 5-10%

#### 3. Очень маленькие файлы (<10 rows) - НИЗКИЙ ПРИОРИТЕТ
**Текущая производительность:**
- Tiny (5 rows): **1.66x медленнее**
- Small (10 rows): **1.14x медленнее**

**Причины:**
- Overhead инициализации парсера
- Overhead вызовов Python-C++
- Размер чанка слишком большой для таких файлов

**Решения:**
1. **Оптимизировать для очень маленьких файлов**
   - Использовать специальный путь для файлов <100 байт
   - Парсить весь файл за один раз без batch processing
   - Ожидаемый прирост: 30-50%

#### 4. Комбинация quotes+unicode - СРЕДНИЙ ПРИОРИТЕТ
**Текущая производительность:**
- Medium with quotes+unicode: **1.08x медленнее**

**Причины:**
- Комбинация проверок для кавычек и unicode
- Дополнительные проверки при создании Python объектов

**Решения:**
1. **Оптимизировать проверку ASCII для полей с кавычками**
   - Кэшировать результат проверки ASCII для чанка
   - Использовать более эффективную проверку
   - Ожидаемый прирост: 5-10%

## Приоритеты оптимизации

### Приоритет 1: Большие файлы (>5000 rows)
**Ожидаемый эффект:** Улучшение с 2.48x медленнее до 1.2x быстрее
**Сложность:** Средняя
**Время:** 2-3 часа

### Приоритет 2: Широкие файлы (50 полей)
**Ожидаемый эффект:** Улучшение с 1.14x медленнее до 1.1x быстрее
**Сложность:** Низкая-Средняя
**Время:** 1-2 часа

### Приоритет 3: Комбинация quotes+unicode
**Ожидаемый эффект:** Улучшение с 1.08x медленнее до 1.05x быстрее
**Сложность:** Низкая
**Время:** 30-60 минут

### Приоритет 4: Очень маленькие файлы
**Ожидаемый эффект:** Улучшение с 1.66x медленнее до 1.2x быстрее
**Сложность:** Низкая
**Время:** 30-60 минут

## Конкретные шаги оптимизации

### Шаг 1: Оптимизация больших файлов
1. Увеличить размер чанка для файлов >1MB до 512KB-1MB
2. Оптимизировать циклы в `parse_chunk` - убрать лишние проверки
3. Использовать более агрессивный batch processing

### Шаг 2: Оптимизация широких файлов
1. Улучшить оценку количества полей перед парсингом
2. Предварительно резервировать память для всех полей
3. Оптимизировать поиск разделителей с помощью SIMD

### Шаг 3: Оптимизация комбинации quotes+unicode
1. Кэшировать результат проверки ASCII для чанка
2. Использовать более эффективную проверку unicode

### Шаг 4: Оптимизация маленьких файлов
1. Добавить специальный путь для файлов <100 байт
2. Парсить весь файл за один раз без batch processing




